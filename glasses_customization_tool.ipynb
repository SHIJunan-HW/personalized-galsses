{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c9276a-38c5-495f-80f2-1e2276ad2351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n",
      "Model successfully loaded!\n",
      "Model checkpoint: C:\\Users\\34568\\Desktop\\GlassesGAN/deeplab_epoch_19.pth (valid)\n",
      "DeepLab script: C:\\Users\\34568\\Desktop\\GlassesGAN/GlassesGAN_release/datasetGAN_release/datasetGAN\\test_deeplab_cross_validation.py (valid)\n",
      "\n",
      "Removing temporary folder\n",
      "\n",
      "Copying model to temporary working directory\n",
      "Aligned image has shape: (1024, 1024)\n",
      "Inference took 0.6252 seconds.\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:04,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:05,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:06,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:07,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:08,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:08,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:09,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:09,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 20\n",
      "Testing Data length, 20\n",
      "\n",
      "\n",
      "Loading the processed images\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 1\n",
      "Testing Data length, 1\n",
      "\n",
      "\n",
      "Loading the processed images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, FloatSlider, Button, Output\n",
    "\n",
    "# 设置项目路径（根据你自己的路径修改）\n",
    "base_working_dir = r'C:\\Users\\34568\\Desktop\\GlassesGAN'\n",
    "repo_name_dir = 'GlassesGAN_release'\n",
    "msvc_path = r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64\"\n",
    "os.environ[\"PATH\"] = msvc_path + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "# 切换到项目目录并导入核心类\n",
    "os.chdir(f'{base_working_dir}/{repo_name_dir}')\n",
    "from glasses_vton_inference import glasses_vton_inference\n",
    "\n",
    "glasses_option = 'RG'\n",
    "chosen_deeplab_epoch = 19\n",
    "fitted_pca_fp = f'{base_working_dir}/fitted_pca_celebhq_dataset_results.joblib'\n",
    "ave_add_glasses_diff_fp = f'{base_working_dir}/aveglassesdiff_celebhq_dataset_results_RG.npy'\n",
    "resume_model_ckpt = f'{base_working_dir}/deeplab_epoch_{chosen_deeplab_epoch}.pth'\n",
    "\n",
    "gvton = glasses_vton_inference(\n",
    "    fitted_pca_fp=fitted_pca_fp,\n",
    "    ave_add_glasses_diff_fp=ave_add_glasses_diff_fp,\n",
    "    base_working_dir=base_working_dir,\n",
    "    temp_save_folder=f'{base_working_dir}/tempfolder',\n",
    "    resume_model_ckpt=resume_model_ckpt,\n",
    "    deeplab_script_location=f'{base_working_dir}/{repo_name_dir}/datasetGAN_release/datasetGAN',\n",
    "    chosen_deeplab_epoch=chosen_deeplab_epoch,\n",
    "    load_loc=base_working_dir,\n",
    "    use_full_glasses_or_frames_mask='frames',\n",
    "    run_tests=False,\n",
    "    outer_dilation_factor=5,\n",
    "    outer_blur_factor=12,\n",
    "    inner_blur_factor=5,\n",
    "    ideal_avg_glasses_frame_area=0.020,\n",
    "    auto_clean=True\n",
    ")\n",
    "\n",
    "# ========== 定义处理函数 ========== \n",
    "def apply_glasses(latent, input_image, edit_image, size, height, squareness, round_shrink, cateye, thicken):\n",
    "    # 反转滑块方向\n",
    "    pca_values = [-size, -height, squareness, round_shrink, -cateye, thicken]\n",
    "\n",
    "    # 更新 latent\n",
    "    for PC_num, PC_bias in enumerate(pca_values):\n",
    "        run_gen = (PC_num == 5)\n",
    "        img, latent = gvton.e4e.run_gen_add_pc_direction_bias(\n",
    "            start_latent=latent,\n",
    "            fitted_pca=gvton.fitted_pca,\n",
    "            bias=PC_bias,\n",
    "            PC_num=PC_num,\n",
    "            run_gen=run_gen\n",
    "        )\n",
    "\n",
    "    blends, _, _ = gvton.blend_in_edits(edits=[img], input_image=input_image)\n",
    "\n",
    "    # 显示图像\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(input_image)\n",
    "    axes[0].set_title(\"Input\")\n",
    "    axes[1].imshow(edit_image)\n",
    "    axes[1].set_title(\"Default Glasses\")\n",
    "    axes[2].imshow(blends[0])\n",
    "    axes[2].set_title(\"Customized Glasses\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========== 初始化加载图像并生成初始结果 ==========\n",
    "\n",
    "# 指定图片路径\n",
    "image_path = f\"{base_working_dir}/{repo_name_dir}/imgtest/01.jpg\"\n",
    "input_image, result_image, base_latent = gvton.embed_input_image(image_path, show_plots=False)\n",
    "start_latent, edit_image, _ = gvton.add_avg_glasses(input_image, base_latent, base_bias=1, show_plots=False, auto_pick_bias=True, return_blended_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f398247d-4e70-42e6-874c-99eda1234b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15b892140c4f70b06266f2f4c26bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=6.0, description='Size:', max=10.0, min=-5.0, step=0.5), Float…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534b6b84084644b5bca081651075e8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# ========== 构建交互控件 ==========\n",
    "\n",
    "size_slider = FloatSlider(value=6.0, min=-5, max=10, step=0.5, description='Size:')\n",
    "height_slider = FloatSlider(value=-9.0, min=-10, max=4, step=0.5, description='Height:')\n",
    "squareness_slider = FloatSlider(value=8.0, min=-4, max=20, step=0.5, description='Squareness:')\n",
    "round_shrink_slider = FloatSlider(value=0.0, min=-20, max=20, step=0.5, description='Round Shrink:')\n",
    "cateye_slider = FloatSlider(value=1.5, min=-15, max=20, step=0.5, description='Cateye:')\n",
    "thicken_slider = FloatSlider(value=6.5, min=-10, max=10, step=0.5, description='Thicken:')\n",
    "\n",
    "# 添加一个按钮\n",
    "run_button = Button(description=\"应用调整\", button_style='success')\n",
    "output = Output()\n",
    "\n",
    "# 定义响应函数（只需更新 latent 和显示新图像）\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        apply_glasses(\n",
    "            latent=start_latent,\n",
    "            input_image=input_image,\n",
    "            edit_image=edit_image,\n",
    "            size=size_slider.value,\n",
    "            height=height_slider.value,\n",
    "            squareness=squareness_slider.value,\n",
    "            round_shrink=round_shrink_slider.value,\n",
    "            cateye=cateye_slider.value,\n",
    "            thicken=thicken_slider.value\n",
    "        )\n",
    "\n",
    "# 绑定按钮点击事件\n",
    "run_button.on_click(on_button_click)\n",
    "\n",
    "# 布局控件\n",
    "controls = VBox([\n",
    "    HBox([size_slider, height_slider]),\n",
    "    HBox([squareness_slider, round_shrink_slider]),\n",
    "    HBox([cateye_slider, thicken_slider]),\n",
    "    run_button\n",
    "])\n",
    "\n",
    "# 显示界面\n",
    "display(controls, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be27b48-8623-4ca4-ac58-687717d86f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
