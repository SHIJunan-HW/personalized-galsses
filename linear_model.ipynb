{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41af2e4b-329a-42b0-9a23-155015cb1b4e",
   "metadata": {},
   "source": [
    "# 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a630fe42-9468-40e5-8804-9564589bad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pickle\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "# 设置中文字体（全局设置）\n",
    "\n",
    "font_path = r\"C:\\Users\\34568\\simhei.ttf\"  #字体路径\n",
    "chinese_font = FontProperties(fname=font_path)\n",
    "mpl.rcParams[\"font.family\"] = chinese_font.get_name()  # 设置字体名称\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "base_working_dir = r'C:\\Users\\34568\\Desktop\\GlassesGAN'\n",
    "repo_name_dir = 'GlassesGAN_release'\n",
    "msvc_path = r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64\"\n",
    "os.environ[\"PATH\"] = msvc_path + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "predictor_path = r\"C:\\Users\\34568\\Desktop\\GlassesGAN\\GlassesGAN_release\\encoder4editing\\shape_predictor_68_face_landmarks.dat\"\n",
    "image_path = r\"imgtest/002.jpg\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d8e4a-a5de-4c7c-885f-aa1b0f4ca150",
   "metadata": {},
   "source": [
    "# 获取人脸关键参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25efebe-763b-4c85-bbbd-a3e7eb28d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "眼睛间距: 42.03 像素, 眼睛间距与脸宽比值: 0.46\n",
      "眼睛高度: 5.00 像素, 眼睛高度与眼睛间距比值: 0.12\n",
      "鼻梁宽度: 16.03 像素, 鼻梁宽度与脸宽比值: 0.18\n",
      "下巴高度: 39.00 像素, 下巴高度与鼻梁高度比值: 1.22\n",
      "面部高度: 71.00 像素, 面部宽高比: 0.78\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray)\n",
    "\n",
    "for face in faces:\n",
    "    landmarks = predictor(gray, face)\n",
    "    \n",
    "    # 眼睛中心点\n",
    "    left_eye_center = (landmarks.part(36).x + landmarks.part(39).x) / 2, (landmarks.part(36).y + landmarks.part(39).y) / 2\n",
    "    right_eye_center = (landmarks.part(42).x + landmarks.part(45).x) / 2, (landmarks.part(42).y + landmarks.part(45).y) / 2\n",
    "    \n",
    "    # 眼睛间距\n",
    "    eye_distance = np.linalg.norm(np.array(left_eye_center) - np.array(right_eye_center))  # 眼睛间距\n",
    "    \n",
    "    # 脸宽\n",
    "    left_cheek = (landmarks.part(0).x, landmarks.part(0).y)\n",
    "    right_cheek = (landmarks.part(16).x, landmarks.part(16).y)\n",
    "    face_width = np.linalg.norm(np.array(left_cheek) - np.array(right_cheek))  # 脸宽\n",
    "    \n",
    "    # 眼睛高度（垂直方向）\n",
    "    eye_height = np.abs(landmarks.part(37).y - landmarks.part(41).y)  # 左眼上下高度差\n",
    "    \n",
    "    # 鼻梁宽度和高度\n",
    "    nose_width = np.linalg.norm(np.array((landmarks.part(31).x, landmarks.part(31).y)) - np.array((landmarks.part(35).x, landmarks.part(35).y)))  # 鼻梁宽度\n",
    "    nose_height = np.abs(landmarks.part(27).y - landmarks.part(33).y)  # 鼻梁高度\n",
    "    \n",
    "    # 下巴高度\n",
    "    chin_height = np.abs(landmarks.part(8).y - landmarks.part(33).y)  # 下巴高度（从下巴到鼻尖）\n",
    "    \n",
    "    # 面部高度\n",
    "    face_height = np.abs(landmarks.part(27).y - landmarks.part(8).y)  # 从鼻梁到下巴的高度\n",
    "    \n",
    "    # 计算比值\n",
    "    eye_distance_ratio = eye_distance / face_width  # 眼睛间距与脸宽比值\n",
    "    eye_height_ratio = eye_height / eye_distance  # 眼睛上下高度与眼睛间距比值\n",
    "    nose_width_ratio = nose_width / face_width  # 鼻梁宽度与脸宽比值\n",
    "    face_ratio = face_height / face_width  # 脸型的宽高比\n",
    "    chin_to_nose_ratio = chin_height / nose_height  # 下巴高度与鼻梁高度比值\n",
    "    \n",
    "    # 输出量化参数\n",
    "    print(f\"眼睛间距: {eye_distance:.2f} 像素, 眼睛间距与脸宽比值: {eye_distance_ratio:.2f}\")\n",
    "    print(f\"眼睛高度: {eye_height:.2f} 像素, 眼睛高度与眼睛间距比值: {eye_height_ratio:.2f}\")\n",
    "    print(f\"鼻梁宽度: {nose_width:.2f} 像素, 鼻梁宽度与脸宽比值: {nose_width_ratio:.2f}\")\n",
    "    print(f\"下巴高度: {chin_height:.2f} 像素, 下巴高度与鼻梁高度比值: {chin_to_nose_ratio:.2f}\")\n",
    "    print(f\"面部高度: {face_height:.2f} 像素, 面部宽高比: {face_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b876ff1-c223-4578-9e73-ae4c30b90fba",
   "metadata": {},
   "source": [
    "# 图像初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98586f2-ef9b-4424-8aee-c113402834fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n",
      "Model successfully loaded!\n",
      "Model checkpoint: C:\\Users\\34568\\Desktop\\GlassesGAN/deeplab_epoch_19.pth (valid)\n",
      "DeepLab script: C:\\Users\\34568\\Desktop\\GlassesGAN/GlassesGAN_release/datasetGAN_release/datasetGAN\\test_deeplab_cross_validation.py (valid)\n",
      "\n",
      "Removing temporary folder\n",
      "\n",
      "Copying model to temporary working directory\n",
      "Aligned image has shape: (1024, 1024)\n",
      "Inference took 0.6839 seconds.\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:04,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:05,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:06,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:06,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:06,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:07,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:07,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:08,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:09,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 20\n",
      "Testing Data length, 20\n",
      "\n",
      "\n",
      "Loading the processed images\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 1\n",
      "Testing Data length, 1\n",
      "\n",
      "\n",
      "Loading the processed images\n"
     ]
    }
   ],
   "source": [
    "# 切换到项目目录并导入核心类\n",
    "os.chdir(f'{base_working_dir}/{repo_name_dir}')\n",
    "from glasses_vton_inference import glasses_vton_inference\n",
    "\n",
    "# 初始化参数\n",
    "glasses_option = 'RG'\n",
    "chosen_deeplab_epoch = 19\n",
    "fitted_pca_fp = f'{base_working_dir}/fitted_pca_celebhq_dataset_results.joblib'\n",
    "ave_add_glasses_diff_fp = f'{base_working_dir}/aveglassesdiff_celebhq_dataset_results_RG.npy'\n",
    "resume_model_ckpt = f'{base_working_dir}/deeplab_epoch_{chosen_deeplab_epoch}.pth'\n",
    "\n",
    "# 初始化 GlassesVton 类实例\n",
    "gvton = glasses_vton_inference(\n",
    "    fitted_pca_fp=fitted_pca_fp,\n",
    "    ave_add_glasses_diff_fp=ave_add_glasses_diff_fp,\n",
    "    base_working_dir=base_working_dir,\n",
    "    temp_save_folder=f'{base_working_dir}/tempfolder',\n",
    "    resume_model_ckpt=resume_model_ckpt,\n",
    "    deeplab_script_location=f'{base_working_dir}/GlassesGAN_release/datasetGAN_release/datasetGAN',\n",
    "    chosen_deeplab_epoch=chosen_deeplab_epoch,\n",
    "    load_loc=base_working_dir,\n",
    "    use_full_glasses_or_frames_mask='frames',\n",
    "    run_tests=False,\n",
    "    outer_dilation_factor=5,\n",
    "    outer_blur_factor=12,\n",
    "    inner_blur_factor=5,\n",
    "    ideal_avg_glasses_frame_area=0.020,\n",
    "    auto_clean=True\n",
    ")\n",
    "input_image, result_image, base_latent = gvton.embed_input_image(image_path, show_plots=False)\n",
    "start_latent, edit_image, _ = gvton.add_avg_glasses(input_image, base_latent, base_bias=1, show_plots=False, auto_pick_bias=True, return_blended_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8933e8-d2d2-4baa-b10d-687ca49251da",
   "metadata": {},
   "source": [
    "# 基于上下文老虎机的推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f665f21-7ff3-48c3-97c5-f929e9a4ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlassesRecommender:\n",
    "    \"\"\"眼镜推荐系统（使用已知人脸参数）\"\"\"\n",
    "    def __init__(self, param_ranges=None, alpha=0.2, load_path=None):\n",
    "        self.param_ranges = param_ranges or [\n",
    "            (-5.0, 10.0),    # Size\n",
    "            (-10.0, 4.0),    # Height\n",
    "            (-4.0, 20.0),    # Squareness\n",
    "            (-20.0, 20.0),   # Round_Shrink\n",
    "            (-15.0, 20.0),   # Cateye\n",
    "            (-10.0, 10.0)    # Thicken\n",
    "        ]\n",
    "        self.param_names = [\"Size\", \"Height\", \"Squareness\", \"Round_Shrink\", \"Cateye\", \"Thicken\"]\n",
    "        self.alpha = alpha\n",
    "        self.context_dim = 5\n",
    "        self.param_dim = 6\n",
    "        self.expanded_dim = self.context_dim + self.param_dim + self.context_dim * self.param_dim\n",
    "        self.A = np.eye(self.expanded_dim)\n",
    "        self.b = np.zeros(self.expanded_dim)\n",
    "        self.history = []\n",
    "        if load_path and os.path.exists(load_path):\n",
    "            self.load_model(load_path)\n",
    "    \n",
    "    def build_feature_vector(self, face_features, glass_params):\n",
    "        base_features = np.concatenate([face_features, glass_params])\n",
    "        interaction_terms = np.outer(face_features, glass_params).flatten()\n",
    "        return np.concatenate([base_features, interaction_terms])\n",
    "    \n",
    "    def generate_candidate_params(self, n_candidates=50, strategy='lhs'):\n",
    "        if strategy == 'lhs':\n",
    "            candidates = np.zeros((n_candidates, self.param_dim))\n",
    "            for i, (low, high) in enumerate(self.param_ranges):\n",
    "                segments = np.linspace(0, 1, n_candidates + 1)\n",
    "                points = np.random.uniform(segments[:-1], segments[1:])\n",
    "                np.random.shuffle(points)\n",
    "                candidates[:, i] = low + points * (high - low)\n",
    "            return candidates\n",
    "        else:\n",
    "            return np.array([[np.random.uniform(low, high) for (low, high) in self.param_ranges] for _ in range(n_candidates)])\n",
    "    \n",
    "    def recommend(self, face_features, n_candidates=50, return_all=False):\n",
    "        candidate_params = self.generate_candidate_params(n_candidates)\n",
    "        scores = []\n",
    "        for params in candidate_params:\n",
    "            feature_vector = self.build_feature_vector(face_features, params)\n",
    "            A_inv = inv(self.A)\n",
    "            theta = A_inv @ self.b\n",
    "            expected_reward = theta.dot(feature_vector)\n",
    "            uncertainty = self.alpha * np.sqrt(feature_vector.dot(A_inv).dot(feature_vector))\n",
    "            scores.append(expected_reward + uncertainty)\n",
    "        best_idx = np.argmax(scores)\n",
    "        return (candidate_params[best_idx], candidate_params, scores) if return_all else candidate_params[best_idx]\n",
    "    \n",
    "    def update(self, face_features, glass_params, reward):\n",
    "        feature_vector = self.build_feature_vector(face_features, glass_params)\n",
    "        self.A += np.outer(feature_vector, feature_vector)\n",
    "        self.b += reward * feature_vector\n",
    "        self.history.append({'face_features': face_features, 'glass_params': glass_params, 'reward': reward})\n",
    "        print(f\"模型已更新: 奖励={reward}\")\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        model_data = {'A': self.A, 'b': self.b, 'history': self.history, 'param_ranges': self.param_ranges, 'alpha': self.alpha}\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"模型已保存到: {path}\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            self.A = model_data['A']\n",
    "            self.b = model_data['b']\n",
    "            self.history = model_data['history']\n",
    "            print(f\"模型加载完成\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载模型失败: {e}\")\n",
    "\n",
    "\n",
    "# 生成眼镜图像\n",
    "def generate_and_show_image(glass_params, start_latent, gvton, input_image=None, title=\"推荐眼镜\"):\n",
    "    Size, Height, Squareness, Round_Shrink, Cateye, Thicken = glass_params\n",
    "    num_pcs = 6\n",
    "    latent = start_latent.copy()\n",
    "    for PC_num, PC_bias in enumerate((Size, Height, Squareness, Round_Shrink, Cateye, Thicken)):\n",
    "        run_gen = True if PC_num == (num_pcs - 1) else False\n",
    "        img, latent = gvton.e4e.run_gen_add_pc_direction_bias(\n",
    "            start_latent=latent, fitted_pca=gvton.fitted_pca, bias=PC_bias, PC_num=PC_num, run_gen=run_gen\n",
    "        )\n",
    "    if input_image is not None:\n",
    "        blends, _, _ = gvton.blend_in_edits(edits=[img], input_image=input_image)\n",
    "        result_image = blends[0]\n",
    "    else:\n",
    "        result_image = img\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(result_image)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return result_image\n",
    "\n",
    "def create_recommendation_interface(recommender, gvton, start_latent, input_image=None, \n",
    "                                   eye_distance_ratio=None, eye_height_ratio=None, \n",
    "                                   nose_width_ratio=None, face_ratio=None, chin_to_nose_ratio=None):\n",
    "    output = widgets.Output()\n",
    "    save_output = widgets.Output()\n",
    "    \n",
    "    # 检查参数是否有效\n",
    "    required_params = [\n",
    "        eye_distance_ratio, eye_height_ratio, nose_width_ratio,\n",
    "        face_ratio, chin_to_nose_ratio\n",
    "    ]\n",
    "    \n",
    "    if any(param is None for param in required_params):\n",
    "        with output:\n",
    "            print(\"错误：人脸特征参数存在未赋值的变量！\")\n",
    "            print(\"请确保以下参数均已正确赋值：\")\n",
    "            print(\"  eye_distance_ratio, eye_height_ratio, nose_width_ratio\")\n",
    "            print(\"  face_ratio, chin_to_nose_ratio\")\n",
    "        return  # 终止函数，避免后续错误\n",
    "    \n",
    "    # 显示已知参数\n",
    "    with output:\n",
    "        print(\"已加载人脸特征参数:\")\n",
    "        print(f\"  眼睛间距/脸宽: {eye_distance_ratio:.2f}\")\n",
    "        print(f\"  眼睛高度/眼睛间距: {eye_height_ratio:.2f}\")\n",
    "        print(f\"  鼻梁宽度/脸宽: {nose_width_ratio:.2f}\")\n",
    "        print(f\"  脸高/脸宽: {face_ratio:.2f}\")\n",
    "        print(f\"  下巴高度/鼻梁高度: {chin_to_nose_ratio:.2f}\")\n",
    "    \n",
    "    # 推荐按钮\n",
    "    recommend_btn = widgets.Button(description='获取推荐', layout=widgets.Layout(width='150px'))\n",
    "    \n",
    "    rating_buttons = [\n",
    "        widgets.Button(\n",
    "            description='非常不喜欢',\n",
    "            layout=widgets.Layout(width='120px'),\n",
    "            style={'button_color': '#FF6B6B'},  # 深红色\n",
    "            tooltip='奖励值: -0.3'\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='不喜欢',\n",
    "            layout=widgets.Layout(width='120px'),\n",
    "            style={'button_color': '#FFD166'},  # 浅红色\n",
    "            tooltip='奖励值: -0.1'\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='一般',\n",
    "            layout=widgets.Layout(width='120px'),\n",
    "            style={'button_color': '#FFFFFF', 'text_color': '#000000'},  # 白色（黑字）\n",
    "            tooltip='奖励值: 0'\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='喜欢',\n",
    "            layout=widgets.Layout(width='120px'),\n",
    "            style={'button_color': '#66D2A0'},  # 浅绿色\n",
    "            tooltip='奖励值: 0.1'\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='非常喜欢',\n",
    "            layout=widgets.Layout(width='120px'),\n",
    "            style={'button_color': '#06D6A0'},  # 深绿色\n",
    "            tooltip='奖励值: 0.3'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 奖励值映射（按钮索引对应奖励值）\n",
    "    reward_mapping = [-0.3, -0.1, 0, 0.1, 0.3]\n",
    "    \n",
    "    # 眼镜参数微调滑块\n",
    "    param_sliders = [\n",
    "        widgets.FloatSlider(\n",
    "            min=low, max=high, step=0.5, value=0,\n",
    "            description=name, layout=widgets.Layout(width='500px')\n",
    "        )\n",
    "        for name, (low, high) in zip(recommender.param_names, recommender.param_ranges)\n",
    "    ]\n",
    "    \n",
    "    # 微调按钮\n",
    "    apply_btn = widgets.Button(description='应用微调')\n",
    "    regenerate_btn = widgets.Button(description='重新生成图像')\n",
    "    \n",
    "    # 模型保存控件\n",
    "    save_path = widgets.Text(value='glasses_model.pkl', description='保存路径:')\n",
    "    save_btn = widgets.Button(description='保存模型')\n",
    "    \n",
    "    # 状态变量\n",
    "    current_face_features = np.array([\n",
    "        eye_distance_ratio, eye_height_ratio, nose_width_ratio, face_ratio, chin_to_nose_ratio\n",
    "    ])\n",
    "    current_params = None\n",
    "    current_score = None\n",
    "    current_image = None\n",
    "    \n",
    "    def on_recommend_click(b):\n",
    "        nonlocal current_params, current_score, current_image\n",
    "        \n",
    "        # 基于已知参数获取推荐\n",
    "        best_params, all_params, all_scores = recommender.recommend(\n",
    "            current_face_features, n_candidates=50, return_all=True\n",
    "        )\n",
    "        current_params = best_params\n",
    "        current_score = all_scores[np.argmax(all_scores)]\n",
    "        \n",
    "        # 更新微调滑块\n",
    "        for i, s in enumerate(param_sliders):\n",
    "            s.value = best_params[i]\n",
    "        \n",
    "        # 显示结果\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"推荐参数 (匹配度: {current_score:.4f}):\")\n",
    "            for name, val in zip(recommender.param_names, best_params):\n",
    "                print(f\"  {name}: {val:.2f}\")\n",
    "            \n",
    "            # 生成图像\n",
    "            print(\"\\n生成推荐眼镜图像:\")\n",
    "            current_image = generate_and_show_image(\n",
    "                best_params, start_latent, gvton, input_image,\n",
    "                title=f\"推荐眼镜 (匹配度: {current_score:.4f})\"\n",
    "            )\n",
    "            \n",
    "            # 显示交互按钮\n",
    "            display(widgets.Label(\"请评价推荐结果:\"))\n",
    "            display(widgets.HBox(rating_buttons))  # 显示5个评分按钮\n",
    "            display(widgets.Label(\"微调参数:\"))\n",
    "            display(widgets.VBox(param_sliders))\n",
    "            display(widgets.HBox([apply_btn, regenerate_btn]))\n",
    "    \n",
    "    def on_rating_click(b):\n",
    "        nonlocal current_params\n",
    "        if current_params is not None:\n",
    "            # 获取点击的按钮索引，映射到奖励值\n",
    "            btn_index = rating_buttons.index(b)\n",
    "            reward = reward_mapping[btn_index]\n",
    "            # 更新模型\n",
    "            recommender.update(current_face_features, current_params, reward)\n",
    "            # 重新推荐\n",
    "            with output:\n",
    "                print(f\"\\n已收到评价: {b.description} (奖励值: {reward})，正在更新推荐...\")\n",
    "            on_recommend_click(None)\n",
    "    \n",
    "    def on_apply_click(b):\n",
    "        nonlocal current_params, current_score, current_image\n",
    "        if current_face_features is None:\n",
    "            return\n",
    "        \n",
    "        # 获取微调后的参数\n",
    "        tweaked_params = np.array([s.value for s in param_sliders])\n",
    "        \n",
    "        # 计算新分数\n",
    "        feature_vector = recommender.build_feature_vector(current_face_features, tweaked_params)\n",
    "        A_inv = inv(recommender.A)\n",
    "        theta = A_inv @ recommender.b\n",
    "        current_score = theta.dot(feature_vector)\n",
    "        current_params = tweaked_params\n",
    "        \n",
    "        # 显示微调结果\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"微调后的参数 (匹配度: {current_score:.4f}):\")\n",
    "            for name, val in zip(recommender.param_names, tweaked_params):\n",
    "                print(f\"  {name}: {val:.2f}\")\n",
    "            \n",
    "            # 生成新图像\n",
    "            print(\"\\n生成微调后的眼镜图像:\")\n",
    "            current_image = generate_and_show_image(\n",
    "                tweaked_params, start_latent, gvton, input_image,\n",
    "                title=f\"微调眼镜 (匹配度: {current_score:.4f})\"\n",
    "            )\n",
    "            \n",
    "            # 显示交互按钮\n",
    "            display(widgets.Label(\"请评价微调结果:\"))\n",
    "            display(widgets.HBox(rating_buttons))\n",
    "            display(widgets.Label(\"微调参数:\"))\n",
    "            display(widgets.VBox(param_sliders))\n",
    "            display(widgets.HBox([apply_btn, regenerate_btn]))\n",
    "    \n",
    "    def on_regenerate_click(b):\n",
    "        nonlocal current_image\n",
    "        if current_params is not None:\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"重新生成图像:\")\n",
    "                current_image = generate_and_show_image(\n",
    "                    current_params, start_latent, gvton, input_image,\n",
    "                    title=f\"眼镜图像 (匹配度: {current_score:.4f})\"\n",
    "                )\n",
    "                display(widgets.Label(\"请评价图像:\"))\n",
    "                display(widgets.HBox(rating_buttons))\n",
    "                display(widgets.Label(\"微调参数:\"))\n",
    "                display(widgets.VBox(param_sliders))\n",
    "                display(widgets.HBox([apply_btn, regenerate_btn]))\n",
    "    \n",
    "    def on_save_click(b):\n",
    "        with save_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                recommender.save_model(save_path.value)\n",
    "            except Exception as e:\n",
    "                print(f\"保存失败: {e}\")\n",
    "    \n",
    "    # 绑定事件\n",
    "    recommend_btn.on_click(on_recommend_click)\n",
    "    for btn in rating_buttons:\n",
    "        btn.on_click(on_rating_click)  # 绑定评分按钮点击事件\n",
    "    apply_btn.on_click(on_apply_click)\n",
    "    regenerate_btn.on_click(on_regenerate_click)\n",
    "    save_btn.on_click(on_save_click)\n",
    "    \n",
    "    # 界面布局\n",
    "    input_box = widgets.VBox([\n",
    "        recommend_btn\n",
    "    ])\n",
    "    \n",
    "    layout = widgets.VBox([\n",
    "        widgets.HBox([input_box, output]),\n",
    "        widgets.HBox([save_path, save_btn, save_output])\n",
    "    ])\n",
    "    \n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be60eb67-8d9d-4099-b42f-22cf9cea3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f002fbe3d9174a1780ac67c74c995bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Button(description='获取推荐', layout=Layout(width='150px'), style=Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 主程序\n",
    "%matplotlib inline\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建推荐器\n",
    "    recommender = GlassesRecommender(alpha=0.2)\n",
    "    \n",
    "\n",
    "    create_recommendation_interface(\n",
    "         recommender=recommender,\n",
    "         gvton=gvton,\n",
    "         start_latent=start_latent,\n",
    "         input_image=input_image,\n",
    "         eye_distance_ratio=eye_distance_ratio,\n",
    "         eye_height_ratio=eye_height_ratio,\n",
    "         nose_width_ratio=nose_width_ratio,\n",
    "         face_ratio=face_ratio,\n",
    "         chin_to_nose_ratio=chin_to_nose_ratio\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd496133-6a72-4728-8973-2fc609e0a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.25393903,  0.30567357,  0.9901595 , ...,  0.07266595,\n",
       "         -0.06027882,  0.656972  ],\n",
       "        [ 0.21414018,  0.2364703 ,  0.15278353, ..., -0.13440952,\n",
       "          0.24067889,  0.39202434],\n",
       "        [ 0.80745035, -0.14258836,  0.04536586, ...,  0.16175488,\n",
       "          0.07013719,  0.14838156],\n",
       "        ...,\n",
       "        [ 0.31148452,  0.4283461 ,  1.0234812 , ...,  0.0764092 ,\n",
       "          0.03925574,  0.92301476],\n",
       "        [ 0.25456086,  0.31119934,  0.9936857 , ...,  0.07522241,\n",
       "         -0.06113189,  0.66009414],\n",
       "        [ 0.09574604,  0.9423585 ,  1.4009855 , ...,  0.12040075,\n",
       "         -0.15882038,  0.75650615]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5a21f-2423-4c1f-ba90-f03f6d11ceda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
