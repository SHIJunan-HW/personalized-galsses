{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea13a87-464d-4c8b-b547-d7a8bd52faf0",
   "metadata": {},
   "source": [
    "## è¯»å–äººè„¸å…³é”®ç‚¹ï¼Œåšå‡ºåˆå§‹æ¨è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456958d9-ce12-4b9d-9ab2-5eb8100838d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çœ¼ç›é—´è·: 37.50 åƒç´ , çœ¼ç›é—´è·ä¸è„¸å®½æ¯”å€¼: 0.42\n",
      "çœ¼ç›é«˜åº¦: 6.00 åƒç´ , çœ¼ç›é«˜åº¦ä¸çœ¼ç›é—´è·æ¯”å€¼: 0.16\n",
      "é¼»æ¢å®½åº¦: 17.00 åƒç´ , é¼»æ¢å®½åº¦ä¸è„¸å®½æ¯”å€¼: 0.19\n",
      "ä¸‹å·´é«˜åº¦: 44.00 åƒç´ , ä¸‹å·´é«˜åº¦ä¸é¼»æ¢é«˜åº¦æ¯”å€¼: 1.47\n",
      "é¢éƒ¨é«˜åº¦: 74.00 åƒç´ , é¢éƒ¨å®½é«˜æ¯”: 0.83\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# è®¾ç½®æ­£ç¡®çš„å½¢çŠ¶é¢„æµ‹å™¨æ–‡ä»¶è·¯å¾„\n",
    "predictor_path = r\"C:\\Users\\34568\\Desktop\\GlassesGAN\\GlassesGAN_release\\encoder4editing\\shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# åŠ è½½äººè„¸æ£€æµ‹å™¨å’Œå½¢çŠ¶é¢„æµ‹å™¨\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# åŠ è½½å›¾åƒ\n",
    "image_path = r\"input/03.jpg\"  # æ›¿æ¢ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# æ£€æµ‹äººè„¸\n",
    "faces = detector(gray)\n",
    "\n",
    "# æå–é‡åŒ–å‚æ•°\n",
    "for face in faces:\n",
    "    # è·å–é¢éƒ¨å…³é”®ç‚¹\n",
    "    landmarks = predictor(gray, face)\n",
    "    \n",
    "    # çœ¼ç›ä¸­å¿ƒç‚¹\n",
    "    left_eye_center = (landmarks.part(36).x + landmarks.part(39).x) / 2, (landmarks.part(36).y + landmarks.part(39).y) / 2\n",
    "    right_eye_center = (landmarks.part(42).x + landmarks.part(45).x) / 2, (landmarks.part(42).y + landmarks.part(45).y) / 2\n",
    "    \n",
    "    # çœ¼ç›é—´è·\n",
    "    eye_distance = np.linalg.norm(np.array(left_eye_center) - np.array(right_eye_center))  # çœ¼ç›é—´è·\n",
    "    \n",
    "    # è„¸å®½\n",
    "    left_cheek = (landmarks.part(0).x, landmarks.part(0).y)\n",
    "    right_cheek = (landmarks.part(16).x, landmarks.part(16).y)\n",
    "    face_width = np.linalg.norm(np.array(left_cheek) - np.array(right_cheek))  # è„¸å®½\n",
    "    \n",
    "    # çœ¼ç›é«˜åº¦ï¼ˆå‚ç›´æ–¹å‘ï¼‰\n",
    "    eye_height = np.abs(landmarks.part(37).y - landmarks.part(41).y)  # å·¦çœ¼ä¸Šä¸‹é«˜åº¦å·®\n",
    "    \n",
    "    # é¼»æ¢å®½åº¦å’Œé«˜åº¦\n",
    "    nose_width = np.linalg.norm(np.array((landmarks.part(31).x, landmarks.part(31).y)) - np.array((landmarks.part(35).x, landmarks.part(35).y)))  # é¼»æ¢å®½åº¦\n",
    "    nose_height = np.abs(landmarks.part(27).y - landmarks.part(33).y)  # é¼»æ¢é«˜åº¦\n",
    "    \n",
    "    # ä¸‹å·´é«˜åº¦\n",
    "    chin_height = np.abs(landmarks.part(8).y - landmarks.part(33).y)  # ä¸‹å·´é«˜åº¦ï¼ˆä»ä¸‹å·´åˆ°é¼»å°–ï¼‰\n",
    "    \n",
    "    # é¢éƒ¨é«˜åº¦\n",
    "    face_height = np.abs(landmarks.part(27).y - landmarks.part(8).y)  # ä»é¼»æ¢åˆ°ä¸‹å·´çš„é«˜åº¦\n",
    "    \n",
    "    # è®¡ç®—æ¯”å€¼\n",
    "    eye_distance_ratio = eye_distance / face_width  # çœ¼ç›é—´è·ä¸è„¸å®½æ¯”å€¼\n",
    "    eye_height_ratio = eye_height / eye_distance  # çœ¼ç›ä¸Šä¸‹é«˜åº¦ä¸çœ¼ç›é—´è·æ¯”å€¼\n",
    "    nose_width_ratio = nose_width / face_width  # é¼»æ¢å®½åº¦ä¸è„¸å®½æ¯”å€¼\n",
    "    face_ratio = face_height / face_width  # è„¸å‹çš„å®½é«˜æ¯”\n",
    "    chin_to_nose_ratio = chin_height / nose_height  # ä¸‹å·´é«˜åº¦ä¸é¼»æ¢é«˜åº¦æ¯”å€¼\n",
    "    \n",
    "    # è¾“å‡ºé‡åŒ–å‚æ•°\n",
    "    print(f\"çœ¼ç›é—´è·: {eye_distance:.2f} åƒç´ , çœ¼ç›é—´è·ä¸è„¸å®½æ¯”å€¼: {eye_distance_ratio:.2f}\")\n",
    "    print(f\"çœ¼ç›é«˜åº¦: {eye_height:.2f} åƒç´ , çœ¼ç›é«˜åº¦ä¸çœ¼ç›é—´è·æ¯”å€¼: {eye_height_ratio:.2f}\")\n",
    "    print(f\"é¼»æ¢å®½åº¦: {nose_width:.2f} åƒç´ , é¼»æ¢å®½åº¦ä¸è„¸å®½æ¯”å€¼: {nose_width_ratio:.2f}\")\n",
    "    print(f\"ä¸‹å·´é«˜åº¦: {chin_height:.2f} åƒç´ , ä¸‹å·´é«˜åº¦ä¸é¼»æ¢é«˜åº¦æ¯”å€¼: {chin_to_nose_ratio:.2f}\")\n",
    "    print(f\"é¢éƒ¨é«˜åº¦: {face_height:.2f} åƒç´ , é¢éƒ¨å®½é«˜æ¯”: {face_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2f169c-3d0e-40e3-890a-261bd033dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¢„æµ‹ç»“æœ: classic_square\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# 1ï¸âƒ£ åŠ è½½æ¨¡å‹\n",
    "model = load('decision_tree_model.joblib')\n",
    "\n",
    "# 2ï¸âƒ£ è¾“å…¥å‚æ•°ï¼ˆä½¿ç”¨å­—å…¸æ–¹å¼æ›´æ¸…æ™°ï¼‰\n",
    "new_data_dict = {\n",
    "    'eye_distance_ratio': eye_distance_ratio,\n",
    "    'eye_height_ratio': eye_height_ratio,\n",
    "    'nose_width_ratio': nose_width_ratio,\n",
    "    'face_ratio': face_ratio,\n",
    "    'chin_to_nose_ratio': chin_to_nose_ratio\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸º DataFrameï¼ˆç¡®ä¿åˆ—é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰\n",
    "X_new = pd.DataFrame([new_data_dict])\n",
    "\n",
    "# 4ï¸âƒ£ è¿›è¡Œé¢„æµ‹\n",
    "predicted_class = model.predict(X_new)[0]\n",
    "\n",
    "# 5ï¸âƒ£ è¾“å‡ºæœ€ç»ˆç»“æœ\n",
    "print(\"é¢„æµ‹ç»“æœ:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "664143ee-8bc2-4e70-9ba2-278666763aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é£æ ¼åç§°åˆ—è¡¨\n",
    "glass_style_names = [\n",
    "    'classic_square',\n",
    "    'retro_round',\n",
    "    'cat_eye',\n",
    "    'modern_large',\n",
    "    'sporty',\n",
    "    'minimalist',\n",
    "    'vintage_metal',\n",
    "    'elegant_small_round',\n",
    "    'tech_savvy',\n",
    "    'high_end',\n",
    "    'trendy_youth',\n",
    "    'unique_shape'\n",
    "]\n",
    "\n",
    "# å¯¹åº”çš„ç‰¹å¾å‘é‡ï¼ˆæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª6ç»´å…ƒç»„ï¼‰\n",
    "glass_styles = [\n",
    "    (5.0, -8.0, 10.0, 0.0, -5.0, 2.0),   # classic_square\n",
    "    (6.5, -7.5, 2.0, 10.0, 2.0, 3.5),   # retro_round\n",
    "    (7.0, -5.0, 8.0, 2.0, 12.0, -1.5),  # cat_eye\n",
    "    (8.0, -9.0, 15.0, -2.0, -3.0, 4.0), # modern_large\n",
    "    (6.0, -6.0, 12.0, -3.0, -2.0, 1.0), # sporty\n",
    "    (4.0, -4.0, 4.0, 0.0, -4.0, 0.0),   # minimalist\n",
    "    (5.5, -8.0, 6.0, 5.0, -6.0, -2.0),  # vintage_metal\n",
    "    (3.5, -7.0, 1.0, 8.0, 5.0, 1.5),    # elegant_small_round\n",
    "    (7.5, -5.5, 13.0, -1.0, -8.0, 3.0), # tech_savvy\n",
    "    (8.5, -6.5, 10.0, 1.5, -4.5, 6.0),  # high_end\n",
    "    (6.0, -3.0, 5.0, 6.0, 10.0, 0.0),   # trendy_youth\n",
    "    (4.5, -9.5, 7.0, -5.0, -10.0, 2.5)  # unique_shape\n",
    "]\n",
    "# åˆ›å»ºå­—å…¸ï¼šé£æ ¼å -> å‘é‡\n",
    "style_to_vector = dict(zip(style_names, glass_styles))\n",
    "def get_vector_by_style(style_name):\n",
    "    return style_to_vector.get(style_name, None)\n",
    "\n",
    "vector = get_vector_by_style(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80726f-f7fe-4487-8362-2ad9cd976267",
   "metadata": {},
   "source": [
    "## å›¾ç‰‡åˆå§‹åŒ–å’Œç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f30a495f-6bee-4fd0-b379-34fcf4e4cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n",
      "Model successfully loaded!\n",
      "Model checkpoint: C:\\Users\\34568\\Desktop\\GlassesGAN/deeplab_epoch_19.pth (valid)\n",
      "DeepLab script: C:\\Users\\34568\\Desktop\\GlassesGAN/GlassesGAN_release/datasetGAN_release/datasetGAN\\test_deeplab_cross_validation.py (valid)\n",
      "\n",
      "Removing temporary folder\n",
      "\n",
      "Copying model to temporary working directory\n",
      "Aligned image has shape: (1024, 1024)\n",
      "Inference took 0.0915 seconds.\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:06,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:07,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:07,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:08,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:09,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:09,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:10,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 20\n",
      "Testing Data length, 20\n",
      "\n",
      "\n",
      "Loading the processed images\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 1\n",
      "Testing Data length, 1\n",
      "\n",
      "\n",
      "Loading the processed images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# è®¾ç½®åŸºç¡€è·¯å¾„å’Œç¯å¢ƒå˜é‡\n",
    "base_working_dir = r'C:\\Users\\34568\\Desktop\\GlassesGAN'\n",
    "repo_name_dir = 'GlassesGAN_release'\n",
    "msvc_path = r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64\"\n",
    "os.environ[\"PATH\"] = msvc_path + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "# è¾“å‡ºç›®å½•\n",
    "output_dir = f'{base_working_dir}/generated_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•å¹¶å¯¼å…¥æ ¸å¿ƒç±»\n",
    "os.chdir(f'{base_working_dir}/{repo_name_dir}')\n",
    "from glasses_vton_inference import glasses_vton_inference\n",
    "\n",
    "# åˆå§‹åŒ–å‚æ•°\n",
    "glasses_option = 'RG'\n",
    "chosen_deeplab_epoch = 19\n",
    "fitted_pca_fp = f'{base_working_dir}/fitted_pca_celebhq_dataset_results.joblib'\n",
    "ave_add_glasses_diff_fp = f'{base_working_dir}/aveglassesdiff_celebhq_dataset_results_RG.npy'\n",
    "resume_model_ckpt = f'{base_working_dir}/deeplab_epoch_{chosen_deeplab_epoch}.pth'\n",
    "\n",
    "# åˆå§‹åŒ– GlassesVton ç±»å®ä¾‹\n",
    "gvton = glasses_vton_inference(\n",
    "    fitted_pca_fp=fitted_pca_fp,\n",
    "    ave_add_glasses_diff_fp=ave_add_glasses_diff_fp,\n",
    "    base_working_dir=base_working_dir,\n",
    "    temp_save_folder=f'{base_working_dir}/tempfolder',\n",
    "    resume_model_ckpt=resume_model_ckpt,\n",
    "    deeplab_script_location=f'{base_working_dir}/GlassesGAN_release/datasetGAN_release/datasetGAN',\n",
    "    chosen_deeplab_epoch=chosen_deeplab_epoch,\n",
    "    load_loc=base_working_dir,\n",
    "    use_full_glasses_or_frames_mask='frames',\n",
    "    run_tests=False,\n",
    "    outer_dilation_factor=5,\n",
    "    outer_blur_factor=12,\n",
    "    inner_blur_factor=5,\n",
    "    ideal_avg_glasses_frame_area=0.020,\n",
    "    auto_clean=True\n",
    ")\n",
    "input_image, result_image, base_latent = gvton.embed_input_image(image_path, show_plots=False)\n",
    "start_latent, edit_image, _ = gvton.add_avg_glasses(input_image, base_latent, base_bias=1, show_plots=False, auto_pick_bias=True, return_blended_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f5e73b-a814-43d1-846e-6707cd5df584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_image(image, title='Image', figsize=(4, 4), dpi=150, save_path_name=None):\n",
    "    plt.close('all')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    if isinstance(image, str):\n",
    "        img = plt.imread(image)\n",
    "    else:\n",
    "        img = image\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off') \n",
    "\n",
    "    if save_path_name:\n",
    "        plt.savefig(save_path_name, bbox_inches='tight', dpi=dpi)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782df99-4357-40b1-8b9f-d2f8d9109fab",
   "metadata": {},
   "source": [
    "## å¤šè‡‚è€è™æœº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86584f33-1463-4e43-b25b-5831ab9120de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic_square       : 1.0000\n",
      "retro_round          : 0.3309\n",
      "cat_eye              : 0.1506\n",
      "modern_large         : 0.9548\n",
      "sporty               : 0.9166\n",
      "minimalist           : 0.9305\n",
      "vintage_metal        : 0.8126\n",
      "elegant_small_round  : 0.1092\n",
      "tech_savvy           : 0.9474\n",
      "high_end             : 0.9177\n",
      "trendy_youth         : 0.0000\n",
      "unique_shape         : 0.8494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# è·å–è¯¥æ¬¾å¼çš„ç´¢å¼•\n",
    "initial_style_idx = glass_style_names.index(predicted_class)\n",
    "def get_initial_scores(glass_styles, initial_style_idx, method='cosine'):\n",
    "    glass_array = np.array(glass_styles)\n",
    "    initial_vec = glass_array[initial_style_idx].reshape(1, -1)\n",
    "    \n",
    "    if method == 'cosine':\n",
    "        scores = cosine_similarity(glass_array, initial_vec).flatten()\n",
    "    elif method == 'euclidean':\n",
    "        scores = -np.linalg.norm(glass_array - initial_vec, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'cosine' or 'euclidean'\")\n",
    "    \n",
    "    # å¯é€‰ï¼šå½’ä¸€åŒ–å¾—åˆ†åˆ° [0,1] åŒºé—´\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    \n",
    "    return scores\n",
    "# è®¡ç®—12æ¬¾çœ¼é•œçš„åˆå§‹å¾—åˆ†\n",
    "scores = get_initial_scores(glass_styles, initial_style_idx, method='cosine')\n",
    "\n",
    "# æ‰“å°æ¯æ¬¾çœ¼é•œå’Œå¯¹åº”å¾—åˆ†\n",
    "for name, score in zip(glass_style_names, scores):\n",
    "    print(f\"{name:<20} : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2434355c-e989-4d60-9a25-c3179694f379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0234f599624973b26db44085b81b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æ¨è...\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# è¾“å‡ºå®¹å™¨\n",
    "output = widgets.Output()\n",
    "\n",
    "class MultiArmBanditWithFeedback:\n",
    "    def __init__(self, glass_styles, glass_style_names, initial_scores=None):\n",
    "        self.glass_styles = glass_styles\n",
    "        self.glass_style_names = glass_style_names\n",
    "        self.num_arms = len(glass_styles)\n",
    "        self.rewards = np.zeros(self.num_arms)\n",
    "        self.num_trials = np.zeros(self.num_arms)\n",
    "        self.epsilon = 0.2\n",
    "        \n",
    "        # å­˜å‚¨åˆå§‹å¾—åˆ†\n",
    "        self.initial_scores = initial_scores\n",
    "        if initial_scores is not None:\n",
    "            self.initial_scores = np.array(initial_scores)\n",
    "        \n",
    "    def select_arm(self):\n",
    "        # å½“è¯•éªŒæ¬¡æ•°è¾ƒå°‘æ—¶ï¼ŒåŒæ—¶è€ƒè™‘åˆå§‹å¾—åˆ†å’Œå½“å‰å¥–åŠ±ä¼°è®¡\n",
    "        if np.sum(self.num_trials) < 5 and self.initial_scores is not None:\n",
    "            # ç»“åˆåˆå§‹å¾—åˆ†å’Œå½“å‰å¥–åŠ±ä¼°è®¡\n",
    "            current_estimates = self.rewards / (self.num_trials + 1e-5)\n",
    "            combined_scores = current_estimates * 0.7 + self.initial_scores * 0.3  # åŠ æƒç»„åˆ\n",
    "            return np.argmax(combined_scores)\n",
    "            \n",
    "        # å¦åˆ™ä½¿ç”¨æ ‡å‡†çš„Îµ-è´ªå¿ƒç­–ç•¥\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            return np.argmax(self.rewards / (self.num_trials + 1e-5))\n",
    "        else:\n",
    "            return np.random.choice(range(self.num_arms))\n",
    "\n",
    "    def update(self, arm_index, reward):\n",
    "        self.num_trials[arm_index] += 1\n",
    "        self.rewards[arm_index] += reward\n",
    "\n",
    "    def generate_and_show_image(self, arm_index):\n",
    "        vector = self.glass_styles[arm_index]\n",
    "        Size, Height, Squareness, Round_Shrink, Cateye, Thicken = vector\n",
    "\n",
    "        num_pcs = 6\n",
    "        latent = start_latent.copy()\n",
    "        for PC_num, PC_bias in enumerate((Size, Height, Squareness, Round_Shrink, Cateye, Thicken)):\n",
    "            run_gen = True if PC_num == (num_pcs - 1) else False\n",
    "            img, latent = gvton.e4e.run_gen_add_pc_direction_bias(\n",
    "                start_latent=latent,\n",
    "                fitted_pca=gvton.fitted_pca,\n",
    "                bias=PC_bias,\n",
    "                PC_num=PC_num,\n",
    "                run_gen=run_gen\n",
    "            )\n",
    "\n",
    "        blends, _, _ = gvton.blend_in_edits(edits=[img], input_image=input_image)\n",
    "\n",
    "        # ç»˜åˆ¶æ–°å›¾åƒ\n",
    "        plt.figure(figsize=(4, 4), dpi=150)\n",
    "        plot_single_image(image=blends[0],\n",
    "                          title=f\"Style: {self.glass_style_names[arm_index]}\",\n",
    "                          figsize=(4, 4),\n",
    "                          dpi=150)\n",
    "\n",
    "    def on_like_click(self, arm_index):\n",
    "        print(f\"ğŸ‘ ç”¨æˆ·æ»¡æ„: {self.glass_style_names[arm_index]}\")\n",
    "        self.update(arm_index, reward=0.1)\n",
    "        self.next_step()\n",
    "\n",
    "    def on_dislike_click(self, arm_index):\n",
    "        print(f\"ğŸ‘ ç”¨æˆ·ä¸æ»¡æ„: {self.glass_style_names[arm_index]}\")\n",
    "        self.update(arm_index, reward=-0.1)\n",
    "        self.next_step()\n",
    "\n",
    "    def show_feedback_buttons(self, arm_index):\n",
    "        like_btn = widgets.Button(description=\"æ»¡æ„\")\n",
    "        dislike_btn = widgets.Button(description=\"ä¸æ»¡æ„\")\n",
    "\n",
    "        like_btn.on_click(lambda btn: self.on_like_click(arm_index))\n",
    "        dislike_btn.on_click(lambda btn: self.on_dislike_click(arm_index))\n",
    "\n",
    "        button_box = widgets.HBox([like_btn, dislike_btn])\n",
    "        display(button_box)\n",
    "\n",
    "    def next_step(self):\n",
    "        # å…ˆæ¸…é™¤æ‰€æœ‰ç°æœ‰è¾“å‡º\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            arm_index = self.select_arm()\n",
    "            self.generate_and_show_image(arm_index)\n",
    "            self.show_feedback_buttons(arm_index)\n",
    "            plt.show()  # ç¡®ä¿å›¾åƒæ˜¾ç¤º\n",
    "\n",
    "    def run(self):\n",
    "        print(\"å¼€å§‹æ¨è...\")\n",
    "        with output:\n",
    "            clear_output(wait=True)  # ç¡®ä¿å¼€å§‹æ—¶è¾“å‡ºåŒºåŸŸä¸ºç©º\n",
    "        self.next_step()\n",
    "\n",
    "# å‡è®¾å·²ç»å®šä¹‰äº†plot_single_imageå‡½æ•°\n",
    "def plot_single_image(image, title='Image', figsize=(4, 4), dpi=150, save_path_name=None):\n",
    "    plt.close('all')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    if isinstance(image, str):\n",
    "        img = plt.imread(image)\n",
    "    else:\n",
    "        img = image\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off') \n",
    "\n",
    "    if save_path_name:\n",
    "        plt.savefig(save_path_name, bbox_inches='tight', dpi=dpi)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# å…ˆæ˜¾ç¤º output å®¹å™¨\n",
    "display(output)\n",
    "\n",
    "# å¯åŠ¨æ¨èç³»ç»Ÿï¼Œä¼ å…¥åˆå§‹å¾—åˆ†\n",
    "bandit = MultiArmBanditWithFeedback(glass_styles, glass_style_names, initial_scores=scores)\n",
    "bandit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f54ad7-5660-4b21-936b-67df4a57ba91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
