{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea13a87-464d-4c8b-b547-d7a8bd52faf0",
   "metadata": {},
   "source": [
    "## 读取人脸关键点，做出初始推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456958d9-ce12-4b9d-9ab2-5eb8100838d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "眼睛间距: 37.50 像素, 眼睛间距与脸宽比值: 0.42\n",
      "眼睛高度: 6.00 像素, 眼睛高度与眼睛间距比值: 0.16\n",
      "鼻梁宽度: 17.00 像素, 鼻梁宽度与脸宽比值: 0.19\n",
      "下巴高度: 44.00 像素, 下巴高度与鼻梁高度比值: 1.47\n",
      "面部高度: 74.00 像素, 面部宽高比: 0.83\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 设置正确的形状预测器文件路径\n",
    "predictor_path = r\"C:\\Users\\34568\\Desktop\\GlassesGAN\\GlassesGAN_release\\encoder4editing\\shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# 加载人脸检测器和形状预测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# 加载图像\n",
    "image_path = r\"input/03.jpg\"  # 替换为你的图片路径\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 检测人脸\n",
    "faces = detector(gray)\n",
    "\n",
    "# 提取量化参数\n",
    "for face in faces:\n",
    "    # 获取面部关键点\n",
    "    landmarks = predictor(gray, face)\n",
    "    \n",
    "    # 眼睛中心点\n",
    "    left_eye_center = (landmarks.part(36).x + landmarks.part(39).x) / 2, (landmarks.part(36).y + landmarks.part(39).y) / 2\n",
    "    right_eye_center = (landmarks.part(42).x + landmarks.part(45).x) / 2, (landmarks.part(42).y + landmarks.part(45).y) / 2\n",
    "    \n",
    "    # 眼睛间距\n",
    "    eye_distance = np.linalg.norm(np.array(left_eye_center) - np.array(right_eye_center))  # 眼睛间距\n",
    "    \n",
    "    # 脸宽\n",
    "    left_cheek = (landmarks.part(0).x, landmarks.part(0).y)\n",
    "    right_cheek = (landmarks.part(16).x, landmarks.part(16).y)\n",
    "    face_width = np.linalg.norm(np.array(left_cheek) - np.array(right_cheek))  # 脸宽\n",
    "    \n",
    "    # 眼睛高度（垂直方向）\n",
    "    eye_height = np.abs(landmarks.part(37).y - landmarks.part(41).y)  # 左眼上下高度差\n",
    "    \n",
    "    # 鼻梁宽度和高度\n",
    "    nose_width = np.linalg.norm(np.array((landmarks.part(31).x, landmarks.part(31).y)) - np.array((landmarks.part(35).x, landmarks.part(35).y)))  # 鼻梁宽度\n",
    "    nose_height = np.abs(landmarks.part(27).y - landmarks.part(33).y)  # 鼻梁高度\n",
    "    \n",
    "    # 下巴高度\n",
    "    chin_height = np.abs(landmarks.part(8).y - landmarks.part(33).y)  # 下巴高度（从下巴到鼻尖）\n",
    "    \n",
    "    # 面部高度\n",
    "    face_height = np.abs(landmarks.part(27).y - landmarks.part(8).y)  # 从鼻梁到下巴的高度\n",
    "    \n",
    "    # 计算比值\n",
    "    eye_distance_ratio = eye_distance / face_width  # 眼睛间距与脸宽比值\n",
    "    eye_height_ratio = eye_height / eye_distance  # 眼睛上下高度与眼睛间距比值\n",
    "    nose_width_ratio = nose_width / face_width  # 鼻梁宽度与脸宽比值\n",
    "    face_ratio = face_height / face_width  # 脸型的宽高比\n",
    "    chin_to_nose_ratio = chin_height / nose_height  # 下巴高度与鼻梁高度比值\n",
    "    \n",
    "    # 输出量化参数\n",
    "    print(f\"眼睛间距: {eye_distance:.2f} 像素, 眼睛间距与脸宽比值: {eye_distance_ratio:.2f}\")\n",
    "    print(f\"眼睛高度: {eye_height:.2f} 像素, 眼睛高度与眼睛间距比值: {eye_height_ratio:.2f}\")\n",
    "    print(f\"鼻梁宽度: {nose_width:.2f} 像素, 鼻梁宽度与脸宽比值: {nose_width_ratio:.2f}\")\n",
    "    print(f\"下巴高度: {chin_height:.2f} 像素, 下巴高度与鼻梁高度比值: {chin_to_nose_ratio:.2f}\")\n",
    "    print(f\"面部高度: {face_height:.2f} 像素, 面部宽高比: {face_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2f169c-3d0e-40e3-890a-261bd033dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果: classic_square\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# 1️⃣ 加载模型\n",
    "model = load('decision_tree_model.joblib')\n",
    "\n",
    "# 2️⃣ 输入参数（使用字典方式更清晰）\n",
    "new_data_dict = {\n",
    "    'eye_distance_ratio': eye_distance_ratio,\n",
    "    'eye_height_ratio': eye_height_ratio,\n",
    "    'nose_width_ratio': nose_width_ratio,\n",
    "    'face_ratio': face_ratio,\n",
    "    'chin_to_nose_ratio': chin_to_nose_ratio\n",
    "}\n",
    "\n",
    "# 3️⃣ 将输入数据转换为 DataFrame（确保列顺序与训练时一致）\n",
    "X_new = pd.DataFrame([new_data_dict])\n",
    "\n",
    "# 4️⃣ 进行预测\n",
    "predicted_class = model.predict(X_new)[0]\n",
    "\n",
    "# 5️⃣ 输出最终结果\n",
    "print(\"预测结果:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "664143ee-8bc2-4e70-9ba2-278666763aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 风格名称列表\n",
    "glass_style_names = [\n",
    "    'classic_square',\n",
    "    'retro_round',\n",
    "    'cat_eye',\n",
    "    'modern_large',\n",
    "    'sporty',\n",
    "    'minimalist',\n",
    "    'vintage_metal',\n",
    "    'elegant_small_round',\n",
    "    'tech_savvy',\n",
    "    'high_end',\n",
    "    'trendy_youth',\n",
    "    'unique_shape'\n",
    "]\n",
    "\n",
    "# 对应的特征向量（每个元素是一个6维元组）\n",
    "glass_styles = [\n",
    "    (5.0, -8.0, 10.0, 0.0, -5.0, 2.0),   # classic_square\n",
    "    (6.5, -7.5, 2.0, 10.0, 2.0, 3.5),   # retro_round\n",
    "    (7.0, -5.0, 8.0, 2.0, 12.0, -1.5),  # cat_eye\n",
    "    (8.0, -9.0, 15.0, -2.0, -3.0, 4.0), # modern_large\n",
    "    (6.0, -6.0, 12.0, -3.0, -2.0, 1.0), # sporty\n",
    "    (4.0, -4.0, 4.0, 0.0, -4.0, 0.0),   # minimalist\n",
    "    (5.5, -8.0, 6.0, 5.0, -6.0, -2.0),  # vintage_metal\n",
    "    (3.5, -7.0, 1.0, 8.0, 5.0, 1.5),    # elegant_small_round\n",
    "    (7.5, -5.5, 13.0, -1.0, -8.0, 3.0), # tech_savvy\n",
    "    (8.5, -6.5, 10.0, 1.5, -4.5, 6.0),  # high_end\n",
    "    (6.0, -3.0, 5.0, 6.0, 10.0, 0.0),   # trendy_youth\n",
    "    (4.5, -9.5, 7.0, -5.0, -10.0, 2.5)  # unique_shape\n",
    "]\n",
    "# 创建字典：风格名 -> 向量\n",
    "style_to_vector = dict(zip(style_names, glass_styles))\n",
    "def get_vector_by_style(style_name):\n",
    "    return style_to_vector.get(style_name, None)\n",
    "\n",
    "vector = get_vector_by_style(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80726f-f7fe-4487-8362-2ad9cd976267",
   "metadata": {},
   "source": [
    "## 图片初始化和生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f30a495f-6bee-4fd0-b379-34fcf4e4cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n",
      "Model successfully loaded!\n",
      "Model checkpoint: C:\\Users\\34568\\Desktop\\GlassesGAN/deeplab_epoch_19.pth (valid)\n",
      "DeepLab script: C:\\Users\\34568\\Desktop\\GlassesGAN/GlassesGAN_release/datasetGAN_release/datasetGAN\\test_deeplab_cross_validation.py (valid)\n",
      "\n",
      "Removing temporary folder\n",
      "\n",
      "Copying model to temporary working directory\n",
      "Aligned image has shape: (1024, 1024)\n",
      "Inference took 0.0915 seconds.\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:06,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:07,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:07,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:08,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:09,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:09,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:10,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 20\n",
      "Testing Data length, 20\n",
      "\n",
      "\n",
      "Loading the processed images\n",
      "\n",
      "Saving image and fake groundtruth maps to temporary file location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing image to (512,512,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running deeplab\n",
      "Opt {'exp_dir': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', 'batch_size': 64, 'category': 'face', 'debug': False, 'dim': [512, 512, 5088], 'deeplab_res': 512, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 7, 'stylegan_ver': '1', 'annotation_data_from_w': False, 'annotation_mask_path': './custom_data/annotation/training_data', 'testing_path': 'C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/input_images', 'average_latent': './custom_data/training_latent/avg_latent_stylegan1.npy', 'annotation_image_latent_path': './custom_data/training_latent/latent_stylegan1.npy', 'stylegan_checkpoint': './checkpoints/stylegan_pretrain/karras2019stylegan-ffhq-1024x1024_old_serialization.pt', 'model_num': 10, 'upsample_mode': 'bilinear'}\n",
      "args Namespace(exp='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/face_34.json', resume='C:\\\\Users\\\\34568\\\\Desktop\\\\GlassesGAN/tempfolder/model', cross_validate=False, validation_number=0, chosen_deeplab_epoch=19)\n",
      "Report performance on the best checkpoint\n",
      "Val Data length, 1\n",
      "Testing Data length, 1\n",
      "\n",
      "\n",
      "Loading the processed images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# 设置基础路径和环境变量\n",
    "base_working_dir = r'C:\\Users\\34568\\Desktop\\GlassesGAN'\n",
    "repo_name_dir = 'GlassesGAN_release'\n",
    "msvc_path = r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64\"\n",
    "os.environ[\"PATH\"] = msvc_path + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "# 输出目录\n",
    "output_dir = f'{base_working_dir}/generated_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 切换到项目目录并导入核心类\n",
    "os.chdir(f'{base_working_dir}/{repo_name_dir}')\n",
    "from glasses_vton_inference import glasses_vton_inference\n",
    "\n",
    "# 初始化参数\n",
    "glasses_option = 'RG'\n",
    "chosen_deeplab_epoch = 19\n",
    "fitted_pca_fp = f'{base_working_dir}/fitted_pca_celebhq_dataset_results.joblib'\n",
    "ave_add_glasses_diff_fp = f'{base_working_dir}/aveglassesdiff_celebhq_dataset_results_RG.npy'\n",
    "resume_model_ckpt = f'{base_working_dir}/deeplab_epoch_{chosen_deeplab_epoch}.pth'\n",
    "\n",
    "# 初始化 GlassesVton 类实例\n",
    "gvton = glasses_vton_inference(\n",
    "    fitted_pca_fp=fitted_pca_fp,\n",
    "    ave_add_glasses_diff_fp=ave_add_glasses_diff_fp,\n",
    "    base_working_dir=base_working_dir,\n",
    "    temp_save_folder=f'{base_working_dir}/tempfolder',\n",
    "    resume_model_ckpt=resume_model_ckpt,\n",
    "    deeplab_script_location=f'{base_working_dir}/GlassesGAN_release/datasetGAN_release/datasetGAN',\n",
    "    chosen_deeplab_epoch=chosen_deeplab_epoch,\n",
    "    load_loc=base_working_dir,\n",
    "    use_full_glasses_or_frames_mask='frames',\n",
    "    run_tests=False,\n",
    "    outer_dilation_factor=5,\n",
    "    outer_blur_factor=12,\n",
    "    inner_blur_factor=5,\n",
    "    ideal_avg_glasses_frame_area=0.020,\n",
    "    auto_clean=True\n",
    ")\n",
    "input_image, result_image, base_latent = gvton.embed_input_image(image_path, show_plots=False)\n",
    "start_latent, edit_image, _ = gvton.add_avg_glasses(input_image, base_latent, base_bias=1, show_plots=False, auto_pick_bias=True, return_blended_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f5e73b-a814-43d1-846e-6707cd5df584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_image(image, title='Image', figsize=(4, 4), dpi=150, save_path_name=None):\n",
    "    plt.close('all')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    if isinstance(image, str):\n",
    "        img = plt.imread(image)\n",
    "    else:\n",
    "        img = image\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off') \n",
    "\n",
    "    if save_path_name:\n",
    "        plt.savefig(save_path_name, bbox_inches='tight', dpi=dpi)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782df99-4357-40b1-8b9f-d2f8d9109fab",
   "metadata": {},
   "source": [
    "## 多臂老虎机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86584f33-1463-4e43-b25b-5831ab9120de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic_square       : 1.0000\n",
      "retro_round          : 0.3309\n",
      "cat_eye              : 0.1506\n",
      "modern_large         : 0.9548\n",
      "sporty               : 0.9166\n",
      "minimalist           : 0.9305\n",
      "vintage_metal        : 0.8126\n",
      "elegant_small_round  : 0.1092\n",
      "tech_savvy           : 0.9474\n",
      "high_end             : 0.9177\n",
      "trendy_youth         : 0.0000\n",
      "unique_shape         : 0.8494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 获取该款式的索引\n",
    "initial_style_idx = glass_style_names.index(predicted_class)\n",
    "def get_initial_scores(glass_styles, initial_style_idx, method='cosine'):\n",
    "    glass_array = np.array(glass_styles)\n",
    "    initial_vec = glass_array[initial_style_idx].reshape(1, -1)\n",
    "    \n",
    "    if method == 'cosine':\n",
    "        scores = cosine_similarity(glass_array, initial_vec).flatten()\n",
    "    elif method == 'euclidean':\n",
    "        scores = -np.linalg.norm(glass_array - initial_vec, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'cosine' or 'euclidean'\")\n",
    "    \n",
    "    # 可选：归一化得分到 [0,1] 区间\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    \n",
    "    return scores\n",
    "# 计算12款眼镜的初始得分\n",
    "scores = get_initial_scores(glass_styles, initial_style_idx, method='cosine')\n",
    "\n",
    "# 打印每款眼镜和对应得分\n",
    "for name, score in zip(glass_style_names, scores):\n",
    "    print(f\"{name:<20} : {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2434355c-e989-4d60-9a25-c3179694f379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0234f599624973b26db44085b81b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始推荐...\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 输出容器\n",
    "output = widgets.Output()\n",
    "\n",
    "class MultiArmBanditWithFeedback:\n",
    "    def __init__(self, glass_styles, glass_style_names, initial_scores=None):\n",
    "        self.glass_styles = glass_styles\n",
    "        self.glass_style_names = glass_style_names\n",
    "        self.num_arms = len(glass_styles)\n",
    "        self.rewards = np.zeros(self.num_arms)\n",
    "        self.num_trials = np.zeros(self.num_arms)\n",
    "        self.epsilon = 0.2\n",
    "        \n",
    "        # 存储初始得分\n",
    "        self.initial_scores = initial_scores\n",
    "        if initial_scores is not None:\n",
    "            self.initial_scores = np.array(initial_scores)\n",
    "        \n",
    "    def select_arm(self):\n",
    "        # 当试验次数较少时，同时考虑初始得分和当前奖励估计\n",
    "        if np.sum(self.num_trials) < 5 and self.initial_scores is not None:\n",
    "            # 结合初始得分和当前奖励估计\n",
    "            current_estimates = self.rewards / (self.num_trials + 1e-5)\n",
    "            combined_scores = current_estimates * 0.7 + self.initial_scores * 0.3  # 加权组合\n",
    "            return np.argmax(combined_scores)\n",
    "            \n",
    "        # 否则使用标准的ε-贪心策略\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            return np.argmax(self.rewards / (self.num_trials + 1e-5))\n",
    "        else:\n",
    "            return np.random.choice(range(self.num_arms))\n",
    "\n",
    "    def update(self, arm_index, reward):\n",
    "        self.num_trials[arm_index] += 1\n",
    "        self.rewards[arm_index] += reward\n",
    "\n",
    "    def generate_and_show_image(self, arm_index):\n",
    "        vector = self.glass_styles[arm_index]\n",
    "        Size, Height, Squareness, Round_Shrink, Cateye, Thicken = vector\n",
    "\n",
    "        num_pcs = 6\n",
    "        latent = start_latent.copy()\n",
    "        for PC_num, PC_bias in enumerate((Size, Height, Squareness, Round_Shrink, Cateye, Thicken)):\n",
    "            run_gen = True if PC_num == (num_pcs - 1) else False\n",
    "            img, latent = gvton.e4e.run_gen_add_pc_direction_bias(\n",
    "                start_latent=latent,\n",
    "                fitted_pca=gvton.fitted_pca,\n",
    "                bias=PC_bias,\n",
    "                PC_num=PC_num,\n",
    "                run_gen=run_gen\n",
    "            )\n",
    "\n",
    "        blends, _, _ = gvton.blend_in_edits(edits=[img], input_image=input_image)\n",
    "\n",
    "        # 绘制新图像\n",
    "        plt.figure(figsize=(4, 4), dpi=150)\n",
    "        plot_single_image(image=blends[0],\n",
    "                          title=f\"Style: {self.glass_style_names[arm_index]}\",\n",
    "                          figsize=(4, 4),\n",
    "                          dpi=150)\n",
    "\n",
    "    def on_like_click(self, arm_index):\n",
    "        print(f\"👍 用户满意: {self.glass_style_names[arm_index]}\")\n",
    "        self.update(arm_index, reward=0.1)\n",
    "        self.next_step()\n",
    "\n",
    "    def on_dislike_click(self, arm_index):\n",
    "        print(f\"👎 用户不满意: {self.glass_style_names[arm_index]}\")\n",
    "        self.update(arm_index, reward=-0.1)\n",
    "        self.next_step()\n",
    "\n",
    "    def show_feedback_buttons(self, arm_index):\n",
    "        like_btn = widgets.Button(description=\"满意\")\n",
    "        dislike_btn = widgets.Button(description=\"不满意\")\n",
    "\n",
    "        like_btn.on_click(lambda btn: self.on_like_click(arm_index))\n",
    "        dislike_btn.on_click(lambda btn: self.on_dislike_click(arm_index))\n",
    "\n",
    "        button_box = widgets.HBox([like_btn, dislike_btn])\n",
    "        display(button_box)\n",
    "\n",
    "    def next_step(self):\n",
    "        # 先清除所有现有输出\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            arm_index = self.select_arm()\n",
    "            self.generate_and_show_image(arm_index)\n",
    "            self.show_feedback_buttons(arm_index)\n",
    "            plt.show()  # 确保图像显示\n",
    "\n",
    "    def run(self):\n",
    "        print(\"开始推荐...\")\n",
    "        with output:\n",
    "            clear_output(wait=True)  # 确保开始时输出区域为空\n",
    "        self.next_step()\n",
    "\n",
    "# 假设已经定义了plot_single_image函数\n",
    "def plot_single_image(image, title='Image', figsize=(4, 4), dpi=150, save_path_name=None):\n",
    "    plt.close('all')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    if isinstance(image, str):\n",
    "        img = plt.imread(image)\n",
    "    else:\n",
    "        img = image\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off') \n",
    "\n",
    "    if save_path_name:\n",
    "        plt.savefig(save_path_name, bbox_inches='tight', dpi=dpi)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# 先显示 output 容器\n",
    "display(output)\n",
    "\n",
    "# 启动推荐系统，传入初始得分\n",
    "bandit = MultiArmBanditWithFeedback(glass_styles, glass_style_names, initial_scores=scores)\n",
    "bandit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f54ad7-5660-4b21-936b-67df4a57ba91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
